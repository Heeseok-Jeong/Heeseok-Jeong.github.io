<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <!--Favicon-->
  <link rel="shortcut icon" href="/assets/favicon.ico" type="image/x-icon">

  <!-- Font Awesome -->
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.9.0/css/all.css"
    integrity="sha384-i1LQnF23gykqWXg6jxC2ZbCbUMxyw5gLZY6UiUS98LYV5unm8GWmfkIS6jqJfb4E" crossorigin="anonymous">

  <!-- Spoqa Han Sans -->
  <link href='//spoqa.github.io/spoqa-han-sans/css/SpoqaHanSans-kr.css' rel='stylesheet' type='text/css'>

  <!-- CSS -->
  <link rel="stylesheet" href="/assets/css/main.css">

  <!-- OG Tag -->
  
  <meta name="title" content="Heeseok Jeong-Ustage Day 15" />
  <meta name="author" content="Heeseok Jeong" />
  <meta name="keywords" content="BoostCamp AI Tech" />
  <meta name="description" content="Generative Models" />
  <meta name="robots" content="index,follow" />

  <meta property="og:title" content="Heeseok Jeong-Ustage Day 15" />
  <meta property="og:description" content="Generative Models" />
  <meta property="og:type" content="website, blog" />
  <meta property="og:image"
    content="http://localhost:4000/assets/img/smile.png" />
  <meta property="og:site_name" content="Heeseok Jeong" />
  <meta property="og:url" content="http://localhost:4000/2021/02/05/bcaitech-ustage-day15.html" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Heeseok Jeong-Ustage Day 15" />
  <meta name="twitter:description" content="Generative Models" />
  <meta name="twitter:image"
    content="http://localhost:4000/assets/img/smile.png" />

  <title>Heeseok Jeong-Ustage Day 15</title>
</head>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        TeX: {
          equationNumbers: {
            autoNumber: "AMS"
          }
        },
        tex2jax: {
        inlineMath: [ ['$', '$'] ],
        displayMath: [ ['$$', '$$'] ],
        processEscapes: true,
      }
    });
    MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
          alert("Math Processing Error: "+message[1]);
        });
    MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
          alert("Math Processing Error: "+message[1]);
        });
    </script>
    <script type="text/javascript" async
      src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>


<body>
  <div class="container">
    

<header>
  <nav>
    <ul>
      
      <!-- others -->
      <a href="http://localhost:4000">
        <li class="current btn-nav">Blog</li>
      </a>
      <a href="http://localhost:4000/tags">
        <li class="btn-nav">Tags</li>
      </a>
      <a href="http://localhost:4000/portfolio">
        <li class="btn-nav">Portfolio</li>
      </a>
      
    </ul>
  </nav>
</header>
<div id="post">
  <section class="post-header">
    <h1 class="title">Ustage Day 15</h1>
    <p class="subtitle">Generative Models</p>
    <p class="meta">
      February 5, 2021
    </p>
  </section>
  <section class="post-content">
    <h1 id="목차">목차</h1>

<p><br /></p>

<ul>
  <li><a href="#generative-models">Generative Models</a></li>
  <li><a href="#마스터-클래스">마스터 클래스</a></li>
  <li><a href="#피어-세션">피어 세션</a></li>
  <li><a href="#today-i-felt">Today I Felt</a></li>
</ul>

<p><br /></p>

<hr />

<p><br /></p>

<h1 id="generative-models">Generative Models</h1>

<p><br /></p>

<ul>
  <li>What I can not create, I do not understand. - 리처드 파인만 -</li>
</ul>

<h2 id="introduction">Introduction</h2>

<ul>
  <li>generative model 을 배운다는 것은 어떤걸 의미할까?
    <ul>
      <li>그럴듯한 이미지나 문장을 만드는 것 이상</li>
      <li>만들어내는게 전부가 아님</li>
    </ul>
  </li>
  <li>만약 강아지 이미지들이 주어진다면?
    <ul>
      <li>
        <p><strong>Generation</strong> : 만약 $x_\mathit{new} \sim p(x)$ 를 샘플링하면 $x_\mathit{new}$ 는 강아지처럼 보일 것임 <strong>(sampling)</strong></p>

        <p>→ <strong>implicit model</strong></p>
      </li>
      <li><strong>Density estimation</strong> : p(x) 는 어떤 이미지가 주어졌을 때, 강아지같은지 고양이같은지 구분, 즉 만들어내는거 이상으로 분류(감지) 까지 가능함 <strong>(anomaly detection)</strong>
  → 이렇게 확률까지 얻어내는 모델을 <strong>explicit</strong> 모델이라 함</li>
      <li><strong>Unsupervised representation learning</strong> : 여러 이미지들이 귀, 꼬리들과 같은 공통점이 있다는 것을 우리는 학습할 수 있음 <strong>(feature learning)</strong></li>
    </ul>
  </li>
  <li>p(x) 를 어떻게 만들까?</li>
</ul>

<h3 id="기본-이항-분포">기본 이항 분포</h3>

<ul>
  <li>
    <p>베르누이 분포 : 동전 던지기</p>

    <p>[사진1]</p>
  </li>
  <li>
    <p>카테고리컬 분포 : m 면체 주사위 던지기</p>

    <p>[사진2]</p>
  </li>
  <li>RGB joint distribution (결합 분포) 을 모델링한다면
    <ul>
      <li>(r, g, b) ~ p(R, G, B)</li>
      <li>Number of cases? → 256 x 256 x 256</li>
      <li>파라미터 숫자가 얼마나 필요한가? → 255 x 255 x 255 (너무 많음)
  ⇒ fully dependent 는 너무 많은 파라미터 필요</li>
    </ul>
  </li>
  <li>흑백 이미지 N 개 X1, …, XN 이 있다면
    <ul>
      <li>경우의 수 → 2 x 2 … x 2 = $2^n$</li>
      <li>p(x1, …, xn) 의 파라미터 수는 → n</li>
      <li>$2^n$ 엔트리는 n 으로 설명 가능함. 하지만 이 독립 추정은 모델이 사용할만한 분포로서는 너무 강함
        <ul>
          <li>각각의 픽셀에 대해 파라미터 1 개 필요. n 개가 모두 독립적이므로 다 더하면 n 개.</li>
        </ul>

        <p>⇒ fully independent 는 파라미터는 적지만 말이 안되는 추정</p>

        <p>(Q. 지수가 배수되는 과정 더 알아봐야 함 → 독립이면 다 따로 각각 생각해서 변수 개수는 n 개, 다 더하면됨)</p>
      </li>
    </ul>
  </li>
  <li>Conditional Independence
    <ul>
      <li>위 두 개의 중간 : 체인 룰과 컨디셔널을 이용해서</li>
      <li>
        <p>세 가지 기본적인 룰</p>

        <p>[사진3]</p>
      </li>
      <li>체인룰을 사용하면, joint 분포를 conditional 분포로 바꿔줌
        <ul>
          <li>어떤 것도 바뀌지 않음 → fully dependent 모델 파라미터 수와 같음</li>
          <li>파라미터 수
            <ul>
              <li>p(x1) : 1 param</li>
              <li>p(x2 | x1) : 2 params (one per p(x2 | x1 = 0) and one per p(x2 | x1 = 1))</li>
              <li>p(x3 | x1, x2) : 4 params</li>
              <li>$2^n-1$ 를 따름</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>
        <p>Markov assumtion, 바로 전 입력에 의해 현재 입력 영향</p>

        <p>[사진4]</p>

        <ul>
          <li>파라미터 수 : 2n - 1</li>
          <li>Markov asuumtion 모델을 레버리징하여 파라미터에 대해 exponential reduction (지수를 배수로 줄임) 가능</li>
          <li><strong>Auto-regressive models</strong> 는 이 conditional independency 를 레버리징함.</li>
        </ul>
      </li>
    </ul>

    <p>### Auto-regressive Model</p>

    <ul>
      <li>MNIST 이미지 28x28 짜리 숫자 사진이 있다고 가정하자.</li>
      <li>우리의 목표는 p(x) = p(x1, …, p784) 를 학습하는것, x 는 0 or 1</li>
      <li>어떻게 p(x) 를 파라미터화 할까?
        <ul>
          <li>joint distribution 에 체인룰 적용</li>
        </ul>

        <p>[사진5]</p>

        <p>⇒ auto-regressive model</p>

        <ul>
          <li>자기 회귀 모델은 하나의 정보가 이전 정보들에 의존적인 것
            <ul>
              <li>마코비언처럼 하나의 정보가 이전 정보에만 의존해도 (AROne 모델)</li>
              <li>하나의 정보가 모든 이전 정보에 의존 (ARN 모델)</li>
            </ul>
          </li>
          <li>어떤 이미지를 자기회귀 하려면 랜덤 변수들에 대해 ordering (순서 매기기) 필요함
            <ul>
              <li>순서 매기는 방법에 따라 성능이 달라질 수 있음 (지그재그, 연속 등)</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>joint distribution 에 대해 마코비언 추정을 하거나 다른 conditional independence 추정을 하는 것이 체인룰 입장에서 joint distribution 을 쪼개는 데에 어떤 관계가 있는지 생각할 것</li>
    </ul>
  </li>
</ul>

<h3 id="nade--neural-autoregressive-density-estimator">NADE : Neural Autoregressive Density Estimator</h3>

<p>[사진6]</p>

<ul>
  <li>i 번째 픽셀을 1 ~ i-1 번째 픽셀에 의존하게 만듦</li>
  <li>첫 번째 픽셀의 확률분포는 독립적으로 만들고, 두 번째 픽셀의 확률은 첫 번째 픽셀에 의존하게 (h 가 됨) … 끝까지 진행</li>
  <li>100번째 뉴럴 네트워크 (100번째 픽셀에 대한 확률분포) 만들 때는 99 개의 이전 입력들을 받을 수 있는 뉴럴 네트워크 필요</li>
  <li>NADE 는 explicit 모델 (생성 + 분류(확률계산)) → 주어진 입력에 대해 density 계산 가능</li>
  <li>
    <p>784 개의 바이너리 픽셀 {x1, …, x784} 이 있다면, joint 확률은 아래와 같음</p>

    <p>[사진7]</p>
  </li>
  <li>연속 확률 변수일 때는 마지막 모델에 가우시안 믹스쳐 모델을 사용</li>
</ul>

<h3 id="pixel-rnn">Pixel RNN</h3>

<ul>
  <li>auto-regressive model 정의하는데 RNN 사용 가능</li>
  <li>
    <p>n x n RGB 이미지가 있을 때, R 먼저 만들고 G 만들고 B 만듦</p>

    <p>[사진8]</p>
  </li>
  <li>
    <p>ordering 을 어떻게 하냐에 따라 두 버전 존재</p>

    <p>[사진9]</p>

    <ul>
      <li>Row LSTM : i 번째 픽셀을 만들 때 위쪽 정보 사용 (아래로 진행, 맞나?)</li>
      <li>Diagonal BiLSTM : bidirectional 하면서 자기 이전 정보 모두 사용 (옆으로 진행)</li>
    </ul>
  </li>
</ul>

<h2 id="latent-variable-models">Latent Variable Models</h2>

<ul>
  <li>Kingma 박사가 만듦 (Adam 도 만듦, 박사 논문 읽어보는거 추천)</li>
  <li>Auto-encoder 도 generative model 일까? 사실 그렇지 않음, Variational Auto-encoder 가 일반 Auto-encoder 와 어떤 차이가 있고 어떻게 Variational Auto-encoder 는 generative model 되는지 알 것</li>
</ul>

<h3 id="variational-auto-encoder">Variational Auto-encoder</h3>

<ul>
  <li>Variational inference (VI)
    <ul>
      <li>VI 의 목적은 <strong>variational distribution</strong> 을 <strong>posterior dist</strong>  와 최적의 매치가 되도록 최적화하는 것
        <ul>
          <li>
            <table>
              <tbody>
                <tr>
                  <td>Posterior dist : $p_\theta(z</td>
                  <td>x)$</td>
                </tr>
              </tbody>
            </table>
            <ul>
              <li>관측이 주어졌을 때 관심있는 확률 변수의 확률 분포</li>
              <li>계산하기 힘듦 → 근사하는게 vd</li>
            </ul>
          </li>
          <li>
            <table>
              <tbody>
                <tr>
                  <td>Variational dist : $q_\varnothing(z</td>
                  <td>x)$</td>
                </tr>
              </tbody>
            </table>
            <ul>
              <li>가장 관심있는 pd 를 근사한 것</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>KL 발산을 사용해서 true posterior 를 최소화하는 vd 찾고자 함</li>
    </ul>

    <p>[사진10]</p>

    <ul>
      <li>VD 를 찾는게 목적 (Encoder)</li>
      <li>
        <p>문제는 posterior 를 모르는데 어떻게 이를 근사하는 VD 를 만들 수 있을까?</p>

        <p>→ ELBO 트릭 사용</p>

        <p>[사진11]</p>

        <ul>
          <li>ELBO (Evidence Lower Bound) 를 키움으로써 거리를 줄여줌</li>
          <li>수식 따라가보는거 추천</li>
        </ul>
      </li>
      <li>
        <p>ELBO</p>

        <p>[사진12]</p>

        <ul>
          <li>Reconstruction Term : 인코더를 통해 x 라는 입력을 latent space 로 보냈다가 디코더로 돌아오는 Reconstruction loss 를 줄이는 것</li>
          <li>Prior Fitting Term : x 라는 이미지들을 latent space 에 올림 (점들). 점들이 이루는 분포가 내가 가정하는 latent space 의 prior dist (사전 분포) 와 동시에 만족하는 것과 같음</li>
          <li>엄밀한 의미에서 Implicit model</li>
        </ul>
      </li>
    </ul>

    <p>⇒ 어떤 입력을 latent space 로 보내서 무언가를 찾고 이를 다시 reconstruction 하는 term 만들어지고, generative model 이 되기 위해서는 latent space 된 prior dist 로 z 를 샘플링 하고 디코더를 태워서 나온 아웃풋 (이미지) 를 제너레이션 result 로 봄.</p>

    <ul>
      <li>입란 auto encoder 는 인풋이 latent space 갔다가 output 나오므로 generation model 아님</li>
      <li>Key Limitation
        <ul>
          <li>intractable 모델 (가능성 측정이 힘들다)
            <ul>
              <li>VA 는 Explicit 모델이 아님, 어떤 입력이 주어졌을 때 얘가 얼마나 비슷한지 (likeli 한지) 알기 어려움</li>
            </ul>
          </li>
          <li>prior fitting term 은 반드시 미분가능, 따라서 diverse latent prior dist 사용하기 힘듦</li>
          <li>
            <p>일반적으로 isotropic 가우시안 사용 (모든 아웃풋 차원이 독립)</p>

            <p>[사진13]</p>

            <ul>
              <li>어떤 prior dist 가 가우시안이면, variation dist 와 prior dist 사이의 KL 발산은 위와 같이 close form 으로 나옴</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>가장 큰 단점 : 인코더 활용할 때 prior fitting term 이 KL 발산을 활용하는 것, 가우시안 아닌 경우 활용 힘듦</li>
    </ul>
  </li>
</ul>

<h3 id="adversarial-auto-encoder-aae">Adversarial Auto-encoder, AAE</h3>

<ul>
  <li>Gan 을 활용해서 latent dist 사이의 분포를 맞춰줌</li>
  <li>Auto encoder 의 KL 발산에 있는 prior fitting term 을 GAN objective 로 바꾼 것</li>
  <li>
    <p>샘플링 가능한 latent dist 가 있으면 맞춰줄 수 있음 (uniform dist, 가우시안 믹스쳐 등) → 여러 분포 활용 가능하다는게 장점</p>

    <p>[사진14]</p>
  </li>
  <li>성능도 VA 보다 좋을 때가 많음</li>
</ul>

<h3 id="gan">GAN</h3>

<ul>
  <li>
    <p>아이디어 : 도둑 (Generator) 이 위조지폐를 만드는데 이를 잘 분별하는 경찰 (Discriminator) 이 있다. 도둑은 분별된 돈으로 더 진짜같이 만들려하고, 경찰은 위조와 진짜지폐를 봐서 더 잘 구분하려함</p>

    <p>→ 반복함으로써 generator 성능을 높임</p>
  </li>
  <li>two-player game
    <ul>
      <li>한 쪽은 높이고 싶어하고, 한 쪽은 낮추고 싶어함</li>
    </ul>

    <p>[사진15]</p>
  </li>
  <li>장점 : discriminator 가 성능이 좋아짐에 따라 generator 가 좋아진다.</li>
  <li>
    <p>Implicit model</p>

    <p>[사진16]</p>

    <ul>
      <li>z 로 출발해서 제너레이터 통과해서 가짜 만들고 디스크리미네이터는 가짜와 진짜를 보고 판단</li>
    </ul>
  </li>
  <li>
    <p>Discriminator</p>

    <p>[사진17]</p>
  </li>
  <li>Generator
    <ul>
      <li>optimal discriminator 를 집어넣음</li>
    </ul>

    <p>[사진18]</p>
  </li>
  <li>엄밀히 말하면 dis 가 optimal 이라고 가정했을 때, 이를 gen 이 학습하면 위와 같은 식이 나왔는데 실제로는 dis 가 optimal 수렴하는거 보장 힘듦 → gen 식 보장 안됨 (이론적으로는 가능하지만)</li>
  <li>AAE 에 활용</li>
</ul>

<h3 id="dcgan">DCGAN</h3>

<p>[사진19]</p>

<ul>
  <li>기본 GAN 은 MLP, 얘는 이미지에 사용</li>
  <li>LeakyReLU 사용</li>
  <li>이미지 만들 때 좋은 하이퍼파라미터 사용</li>
</ul>

<h3 id="info-gan">Info-GAN</h3>

<ul>
  <li>학습할 때 단순히 z 로만 만드는게 아니라 class c 를 사용해 만들자.</li>
</ul>

<p>[사진20]</p>

<h3 id="text2image">Text2Image</h3>

<ul>
  <li>문장을 사진으로 바꿈</li>
  <li>DALL-E 의 조상</li>
</ul>

<h3 id="puzzle-gan">Puzzle-GAN</h3>

<ul>
  <li>이미지 안에 서브패치 (헤드라이트, 바퀴 등) 들로 원래 이미지 복원하는데 사용</li>
</ul>

<h3 id="cyclegan">CycleGAN</h3>

<ul>
  <li>이미지 사이 도메인 변경, 말→얼룩말 바꾸기</li>
  <li>Cycle-consistency loss 중요</li>
</ul>

<p>[사진21]</p>

<h3 id="star-gan">Star-GAN</h3>

<ul>
  <li>인풋을 어떤 필터에 따라 바꿔줌, 컨트롤 할 수 있게 해줌</li>
  <li>네이버 작품</li>
</ul>

<h3 id="progressive-gan">Progressive-GAN</h3>

<ul>
  <li>센세이션한 성능</li>
  <li>4x4 픽셀 → 8x8 → … → 1024x1024 로 늘려나가면서 학습</li>
  <li>좋은 성능 이미지 만들어냄</li>
</ul>

<p><strong>Further Reading</strong></p>

<ul>
  <li><a href="https://www.youtube.com/watch?v=odpjk7_tGY0&amp;t=69s">1시간 만에 GAN 완전 정복하기</a></li>
  <li><a href="https://arxiv.org/abs/1906.02691">An Introduction to Variational Autoencoders(저자)</a></li>
</ul>

<p><br /></p>

<hr />

<p><br /></p>

<h1 id="마스터-클래스---최성준-교수님">마스터 클래스 - 최성준 교수님</h1>

<h4 id="1-실제-실무에서도-cnn-rnn-을-활용하여-모델을-만드는지-아니면-밑바닥부터-모델을-구축하는지-궁금합니다">1. 실제 실무에서도 CNN, RNN 을 활용하여 모델을 만드는지 아니면 밑바닥부터 모델을 구축하는지 궁금합니다.</h4>

<p>: 파이토치나 텐서플로우 같은 API 당연히 씀. 연구에는 파이토치, 서비스는 텐서플로우 더 씀</p>

<h4 id="2-실습시간에-배운-코드들을-어느정도까지-익혀야-하는지-궁금합니다-코드를-밑바닥부터-구현-가능한-정도까지-익히는-것이-시간이-오래걸리더라도-투자할만한가요">2. 실습시간에 배운 코드들을 어느정도까지 익혀야 하는지 궁금합니다. 코드를 밑바닥부터 구현 가능한 정도까지 익히는 것이 시간이 오래걸리더라도 투자할만한가요?</h4>

<p>: 연구에서는 밑바닥부터 하는게 좋고 실무에서는 툴 쓰면서 가독성 좋게 잘 쓰면 됨</p>

<h4 id="3-국내에서-석사-박사를-하신-걸로-아는데-영어-공부는-어떻게-하셨나요-회화나-쓰기-역량은-어떻게-쌓으셨는지-궁금합니다">3. 국내에서 석사, 박사를 하신 걸로 아는데 영어 공부는 어떻게 하셨나요? 회화나 쓰기 역량은 어떻게 쌓으셨는지 궁금합니다.</h4>

<p>: 디즈니에서 일할 때 영어 쓸 수 박에 없는 환경</p>

<h4 id="4-논문을-보는-특별한-팁">4. 논문을 보는 특별한 팁</h4>

<p>: 이 논문을 내가 실험할거다 하면 실험 섹션을 많이 봄 (세팅, 알고리즘 등). 일반적으로는 인트로덕션 (이 연구를 왜하게 됐는지) 을 더 봄 (앞으로 어떤걸 할지도 알 수 있어서)</p>

<h4 id="5-ai-엔지니어의-역량이-무엇이라-생각하시나요-데이터-전처리-및-파이프라인-구축-역량-모델-구현-및-서비스단까지-전달-역량-두가지-중-어떤-역량을-중점으로-가져가야-할까요">5. AI 엔지니어의 역량이 무엇이라 생각하시나요? 데이터 전처리 및 파이프라인 구축 역량, 모델 구현 및 서비스단까지 전달 역량 두가지 중 어떤 역량을 중점으로 가져가야 할까요?</h4>

<p>: 잘 모르겠다. 카카오 브레인에서 일반적으로 뛰어난 AI 엔지니어는 둘 다 잘했음</p>

<h4 id="6-rnn-이나-lstm-같은-모델은-굉장히-복잡해-보이는데-이런-네트워크를-만들기-위한-intuition-은-어디서-얻을-수-있을까요">6. RNN 이나 LSTM 같은 모델은 굉장히 복잡해 보이는데 이런 네트워크를 만들기 위한 intuition 은 어디서 얻을 수 있을까요?</h4>

<p>: 잘 모르겠음. bio-inspired (실제 뇌 구조 영감) 된게 아닐까. 수업에서 말했듯 그럴 필요 없지만 새로운거 만들 때 참고하면 좋음</p>

<h4 id="7-모델을-그림으로-표현할-때-사용하는-툴">7. 모델을 그림으로 표현할 때 사용하는 툴</h4>

<p>: 무식하게 키노트로 그림</p>

<h4 id="8-파라미터를-줄이면-일반화-성능이-오른다고-하셨는데-실제로-많은-태스크에서는-파라미터를-줄이기보다-늘릴수록-성능이-올라가는-경우가-많은거-같습니다-의견이-궁금합니다">8. 파라미터를 줄이면 일반화 성능이 오른다고 하셨는데, 실제로 많은 태스크에서는 파라미터를 줄이기보다 늘릴수록 성능이 올라가는 경우가 많은거 같습니다. 의견이 궁금합니다</h4>

<p>: 원래 이론은 그랬는데 요즘엔 GPT-3, switch-Transformer 등 보면 파라미터 매우 많은데 성능이 올라감. 잘모르겠음. 많은 경우 일반화 성능은 평균보다 워스트 케이스 관점으로 보는듯. 요즘 트렌드는 바뀌고 있다~ 데이터셋이 많다면 무조건 모델 크기를 키우는게 맞지 않나 생각</p>

<h4 id="9-설명을-매우-잘하시는데-강의나-발표-준비할-때-팁이-있을까요">9. 설명을 매우 잘하시는데 강의나 발표 준비할 때 팁이 있을까요?</h4>

<p>: 생존을 위해 열심히 하고 있다. 패스트 캠퍼스에서 강의하면서 도움 많이 되었음. 많이 하면 느는듯. 주변에 똑똑한 사람들이 많은데 이들은 설명을 잘 못함 너무 똑똑해서. 천재가 아니라 더 잘 설명하는게 아닐까 싶다.</p>

<h3 id="라이브-qa">라이브 Q&amp;A</h3>

<h4 id="회사에서-머신러닝-엔지니어-직무를-맡길-때-석사로-기대하는-것과-학사로-기대하는-것이-어떤-차이점이-있을까요">회사에서 머신러닝 엔지니어 직무를 맡길 때 석사로 기대하는 것과 학사로 기대하는 것이 어떤 차이점이 있을까요?</h4>

<p>: 회사마다 다른듯. 삼성같은 대기업이면 학사와 석사의 일이 달라짐. 스타트업이면 상관없이 그냥 잘해야함.</p>

<h4 id="교수님-랩실에-들어가기-위한-지원자격이-궁금합니다">교수님 랩실에 들어가기 위한 지원자격이 궁금합니다</h4>

<p>: 면담해봐야함. 열심히 하려하면 됨. 메일보내면 가능.</p>

<h4 id="디즈니에서-리서쳐로-계실-때-구체적으로-어떤-업무를-하셨는지-간략하게-소개-부탁드립니다">디즈니에서 리서쳐로 계실 때 구체적으로 어떤 업무를 하셨는지 간략하게 소개 부탁드립니다!</h4>

<p>: 대외비. 말할 수 없음. 언론에 나온거로는 사전로봇 활용, 로봇 모션 만듦. 디즈니 리서치 조직은 디즈니 랜드와 월드에 들어가는 솔루션을 제공하는 곳</p>

<h4 id="엔지니어와-연구자-사이에서-고민중인-대학생입니다-대학원에-진학해-연구하고-싶은-마음도-있는데-수학이-어느정도로-중요할까요-르벡적분이나-대학원-수준의-확률론도-중요할까요">엔지니어와 연구자 사이에서 고민중인 대학생입니다. 대학원에 진학해 연구하고 싶은 마음도 있는데 수학이 어느정도로 중요할까요? 르벡적분이나 대학원 수준의 확률론도 중요할까요??</h4>

<p>: 중요. 잘하면 좋음.</p>

<h4 id="최신-연구-트렌드를-캐치하는-팁을-얻고-싶습니다-단순히-논문을-많이-읽어서-트렌드를-잡기에는-매년-나오는-논문의-양도-많고-이들을-선택하는-데도-시간이-너무-많이-소요됩니다-ㅠㅠ">최신 연구 트렌드를 캐치하는 팁을 얻고 싶습니다. 단순히 논문을 많이 읽어서 트렌드를 잡기에는 매년 나오는 논문의 양도 많고 이들을 선택하는 데도 시간이 너무 많이 소요됩니다. ㅠㅠ</h4>

<p>: 논문이 너무 많아서 쉽지 않은 문제. 제일 좋은 팁은 논문 많이 보는 사람 옆에 두면 됨. 찔러보면 자기들이 본 논문 추천해줌. 자기만의 연구 분야가 생기면 연구 트렌드는 덜 중요해짐.</p>

<h4 id="왜-서빙을-할때는-tensorflow가-많이쓰이나요">왜 서빙을 할때는 tensorflow가 많이쓰이나요?</h4>

<p>: 잘 모르지만 파이토치 쓰면 버그가 있다 하더라.</p>

<h4 id="엔지니어를-목표로-하는-캠퍼입니다-모르는게-너무-많기도-하고-공부해야-할-양도-많아보여서-그런지-요즘-대학원-진학에-대한-생각을-다시-해-보게-되었습니다-교수님이-석사혹은-박사로-진학하게-된-계기가-궁금합니다">엔지니어를 목표로 하는 캠퍼입니다! 모르는게 너무 많기도 하고, 공부해야 할 양도 많아보여서 그런지, 요즘 대학원 진학에 대한 생각을 다시 해 보게 되었습니다. 교수님이 석사(혹은 박사)로 진학하게 된 계기가 궁금합니다!</h4>

<p>: 학부 때, 군대 대신 청소로봇 만드는 회사에 있었음. 원래는 학사 마치고 스타트업 만들랬음. 학부 때 지식이 얼마나 미천한지 깨닫고 대학원 감.</p>

<h4 id="self-supervised-learning이하-ssl이-뜰거라-하셨는데-회사에서-뉴스에-감성-score나-tag를-적어놓은-data를-비싸게-사오더라고요-ssl을-이용하면-사온-데이터를-이용해-scoretag-모델을-리버스-엔지니어링-할-수-있나요-이런-모델의-한계는-뭘까요">self supervised learning(이하 ssl)이 뜰거라 하셨는데 회사에서 뉴스에 감성 score나 tag를 적어놓은 data를 비싸게 사오더라고요. ssl을 이용하면 사온 데이터를 이용해 score/tag 모델을 리버스 엔지니어링 할 수 있나요? 이런 모델의 한계는 뭘까요?</h4>

<p>: ssl 컨셉 (라벨 없는 데이터를 활용해보자) 자체가 재밌음. 한계점은 라벨이 없으니 믿을 수 없을 수도 있다?</p>

<h4 id="데이터-파이프라인이라는게-어떤-것인지-감이-안옵니다--dataloader를-말하는-건가요">데이터 파이프라인이라는게 어떤 것인지 감이 안옵니다 .. dataloader를 말하는 건가요?</h4>

<p>: 데이터 모으고 전처리하고 컴퓨터가 읽을 수 있게 하는 과정까지. 제일 중요한거는 전처리 과정 (실제 데이터는 노이즈가 많기 때문)</p>

<h4 id="논문을-보실때-어떠한-기준으로-보는지-또-어떤-내용을-중점적으로-보는지-알려주세요수식을-위주로-결과를-위주로-기술을-위주로-등">논문을 보실때 어떠한 기준으로 보는지 또 어떤 내용을 중점적으로 보는지 알려주세요(수식을 위주로, 결과를 위주로, 기술을 위주로 등)</h4>

<p>: 수식은 어렵고 재미없어서 잘 안보려함. 인트로덕션을 많이 보려함. 이거 보면 기존 문제 (읽지 않은 논문도 알려줘서 좋음) 도 알 수 있음</p>

<h4 id="교수님이-연구실에서-진행하고-계신-연구-분야가-궁금합니다">교수님이 연구실에서 진행하고 계신 연구 분야가 궁금합니다!</h4>

<p>: 로보틱스와 시뮬레이션, 모션. 로봇이 사람과 같이 사는 공간에 오면 움직이는게 필요하므로</p>

<h4 id="슬럼프가-왔을-때-어떻게-극복하셨나요-벽을-느꼈을-때나">슬럼프가 왔을 때 어떻게 극복하셨나요? 벽을 느꼈을 때나..?</h4>

<p>: 지금도 슬럼프. 답없음. 잘모르겠음. 박사 때는 논문만 쓰면 좋았는데 요즘에는 주변에 잘하는 사람 너무 많아서 힘들어 페북에 글썼다가 멘토한테 징징대지 말라고 혼남.</p>

<h4 id="기업에서-리서치를-하신다고-하셨는데-리서치-결과를-실제-서비스에-반영하기-위해-엔지니어는-어떤-일을-하게-되나요-리서쳐와-여러-커뮤니케이션-과정을-거쳐-모델을-개발하게-되는걸까요">기업에서 리서치를 하신다고 하셨는데, 리서치 결과를 실제 서비스에 반영하기 위해 엔지니어는 어떤 일을 하게 되나요? 리서쳐와 여러 커뮤니케이션 과정을 거쳐 모델을 개발하게 되는걸까요?</h4>

<p>: 엔지니어가 다 함. 전처리부터 서빙까지 백엔드 프론트엔드 전부 다함. 커뮤니케이션 중요.</p>

<h4 id="강의를-보면-논문이-나오고-기술이-바뀌는-시기가-엄청-빠른-것-같던데-ai엔지니어로-살려면-새-논문과-신기술을-항상-check해야-하나요-아니면-실무에서-쓰는-모델이나-툴은-덜-민감한-편인지">강의를 보면 논문이 나오고 기술이 바뀌는 시기가 엄청 빠른 것 같던데 AI엔지니어로 살려면 새 논문과 신기술을 항상 check해야 하나요? 아니면 실무에서 쓰는 모델이나 툴은 덜 민감한 편인지..</h4>

<p>: 회사의 기술은 생각보다 쉽게 잘 안바뀜. 리서쳐는 매번 체크해야하지만 엔지니어는 좀 다름.</p>

<h4 id="모델을-만들-때-먼저-수식적으로-연구하고-만드는지-먼저-모델을-만들고-수식으로-증명하는지-궁금합니다">모델을 만들 때 먼저 수식적으로 연구하고 만드는지, 먼저 모델을 만들고 수식으로 증명하는지 궁금합니다.</h4>

<p>: 수식 제대로 증명한 적 거의 없음 어려워서.. 이떄까지 1번 해 봄. 모델 만들때 수식 먼저 적고 코딩함. 증명 잘 안함 교수님은</p>

<h4 id="리서치에는-파이토치를-많이-사용하고-실제-배포-시에는-텐서플로우를-많이-사용한다면-엔지니어로-취직하려면-텐서플로우를-배워야할까요">리서치에는 파이토치를 많이 사용하고 실제 배포 시에는 텐서플로우를 많이 사용한다면 엔지니어로 취직하려면 텐서플로우를 배워야할까요??</h4>

<p>: 엔지니어로 취업하려면 둘 다 할 줄 알아야할듯</p>

<h4 id="석사와-박사">석사와 박사</h4>

<p>: 연구쪽으로 하고 싶으면 무조건 박사. 엔지니어 하고 싶으면 노상관, 실력이 중요. 대학원은 공부를 하는 곳.</p>

<h4 id="다양한-분야-정보를-얻고-흥미-분야를-정하고-싶어요">다양한 분야 정보를 얻고 흥미 분야를 정하고 싶어요</h4>

<p>: 학회 등에서 다양한 사람들 만나서 교류 도움됨. 온라인보다.</p>

<h1 id="피어-세션">피어 세션</h1>

<p><br /></p>

<p><br /></p>

<hr />

<p><br /></p>

<h1 id="today-i-felt">Today I Felt</h1>

<p><br /></p>

  </section>
</div>

<div id="top" class="top-btn" onclick="moveTop()">
  <i class="fas fa-chevron-up"></i>
</div>

<!-- Disqus -->

<div id="comments">
  <div class="border">
    <div id="disqus_thread"></div>
<script type="text/javascript">
  var disqus_shortname = 'heeseok-jeong';
  (function () {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>
<noscript></noscript>
  </div>
</div>


<!-- Footer -->
<footer>
  <div class="footer">
    Copyright © 2019
    <a href="https://github.com/NAYE0NG">Nayeong Kim</a>.
    Powered by Jekyll with
    <a href="https://github.com/naye0ng/Grape-Theme">Grape Theme</a>.
  </div>
</footer>


<script>
  var lastScrollTop = 0;
  window.onscroll = function () {
    var st = document.body.scrollTop || document.documentElement.scrollTop;
    if (st > 250) {
      document.getElementById("top").style.display = "block"
      if (st > lastScrollTop) {
        document.getElementById("top").style.opacity = 0
      } else {
        document.getElementById("top").style.opacity = 1
      }
    } else {
      document.getElementById("top").style.opacity = 0
      if (st > lastScrollTop) {
        document.getElementById("top").style.display = "none"
      }
    }
    lastScrollTop = st <= 0 ? 0 : st;
  }
  function moveTop() {
    document.body.scrollTop = 0
    document.documentElement.scrollTop = 0
  }
</script>
  </div>
</body>

</html>